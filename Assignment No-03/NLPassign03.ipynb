{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucf3uZq9yf4d",
        "outputId": "4b8d9806-c1fa-48d1-b153-6dd8537ea0e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk scikit-learn pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n"
      ],
      "metadata": {
        "id": "Gx0-XjZOyxN1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBLQKbR1y1o8",
        "outputId": "d1fadd00-c901-4ba8-f698-fe5de368f6b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    \"text\": [\n",
        "        \"NLTK is a powerful NLP library!\",\n",
        "        \"Text cleaning is an important step in NLP.\",\n",
        "        \"TF-IDF and Word2Vec are widely used techniques.\"\n",
        "    ],\n",
        "    \"label\": [\"library\", \"process\", \"technique\"]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ul0g2luvy4X0",
        "outputId": "af4d6d28-8d36-4905-9e92-d0e9cc32a5e4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              text      label\n",
            "0                  NLTK is a powerful NLP library!    library\n",
            "1       Text cleaning is an important step in NLP.    process\n",
            "2  TF-IDF and Word2Vec are widely used techniques.  technique\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "8jtPSx53y6GD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = clean_text(text)\n",
        "    words = text.split()  # safe tokenization\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in ENGLISH_STOP_WORDS]\n",
        "    return \" \".join(words)\n"
      ],
      "metadata": {
        "id": "FnR2IHiEy9Mt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"cleaned_text\"] = df[\"text\"].apply(preprocess_text)\n",
        "print(df[[\"text\", \"cleaned_text\"]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFKQTxH4y-gq",
        "outputId": "ab38eabb-0d04-43b5-9ce5-14fbe1c0f8e5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              text  \\\n",
            "0                  NLTK is a powerful NLP library!   \n",
            "1       Text cleaning is an important step in NLP.   \n",
            "2  TF-IDF and Word2Vec are widely used techniques.   \n",
            "\n",
            "                          cleaned_text  \n",
            "0            nltk powerful nlp library  \n",
            "1     text cleaning important step nlp  \n",
            "2  tfidf wordvec widely used technique  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "df[\"label_encoded\"] = label_encoder.fit_transform(df[\"label\"])\n",
        "\n",
        "print(df[[\"label\", \"label_encoded\"]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cuzp5WEMy_vs",
        "outputId": "8c6840fb-e715-4451-cd1f-eab2ba06d544"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       label  label_encoded\n",
            "0    library              0\n",
            "1    process              1\n",
            "2  technique              2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(df[\"cleaned_text\"])\n",
        "\n",
        "tfidf_df = pd.DataFrame(\n",
        "    tfidf_matrix.toarray(),\n",
        "    columns=tfidf_vectorizer.get_feature_names_out()\n",
        ")\n",
        "\n",
        "print(tfidf_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYKB_dFXzClv",
        "outputId": "b329f7e7-dd21-422c-fb30-1f8704d6feb8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   cleaning  important   library       nlp      nltk  powerful      step  \\\n",
            "0  0.000000   0.000000  0.528635  0.402040  0.528635  0.528635  0.000000   \n",
            "1  0.467351   0.467351  0.000000  0.355432  0.000000  0.000000  0.467351   \n",
            "2  0.000000   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
            "\n",
            "   technique      text     tfidf      used    widely   wordvec  \n",
            "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "1   0.000000  0.467351  0.000000  0.000000  0.000000  0.000000  \n",
            "2   0.447214  0.000000  0.447214  0.447214  0.447214  0.447214  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"cleaned_text_and_labels.csv\", index=False)\n",
        "tfidf_df.to_csv(\"tfidf_representation.csv\", index=False)\n",
        "\n",
        "print(\"Files saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6fGSTMZzEJt",
        "outputId": "6348d29d-42d3-43d8-c0e8-adc6c7d5ceb9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iJ19HKOyzFq8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}